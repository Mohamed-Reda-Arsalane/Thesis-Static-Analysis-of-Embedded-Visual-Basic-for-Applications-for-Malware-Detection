"""  
This file contains all the model implemented with sickit learn: SVM, RF, KNN, MLP 
The models can be run in Run_Models.ipynb
"""

from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.metrics import classification_report, confusion_matrix, RocCurveDisplay
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from Utilities import *


idx = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,
       28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]
plt.rcParams["figure.figsize"] = (7, 3)


def KNN(features, labels, n, k, cv=True):
    print("K=", k)
    features = Kbest(features, labels, n)
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels, test_size=0.3, random_state=109)
    print("Shape of samples: ", features.shape)
    print("Shape of Trainng samples: ", X_train.shape)
    print("Shape of Testing Sampless: ", X_test.shape)
    model = KNeighborsClassifier(
        leaf_size=1,  n_neighbors=k, p=1)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print("Accuracy KNN : ", metrics.accuracy_score(y_test, y_pred))
    conf_mat = confusion_matrix(y_test, y_pred)
    print("NPV : ", NPV(conf_mat))
    print("PPV : ", PPV(conf_mat))
    print("Confusion Matrix:")
    print(conf_mat)
    print("Report:")
    print(classification_report(y_test, y_pred))
    svc_disp = RocCurveDisplay.from_estimator(model, X_test, y_test)
    plt.show()
    # plotthreshold(model,X_test)
    # pplotthreshold(model,X_test)
    if cv:
        scores = cross_val_score(model, features, labels, cv=3)
        print("Cross validation cv=3", scores)
        print("Mean Accuracy:", scores.mean())


def MYSVM(features, labels, cv=True):
    X_train_svm, X_test_svm, y_train, y_test = train_test_split(
        features, labels, test_size=0.3, random_state=109)
    print("Shape of samples: ", features.shape)
    clf = svm.SVC(kernel='rbf', gamma=0.7, C=200,
                  probability=True, random_state=109)
    print("traning with test size=30%...")
    clf.fit(X_train_svm, y_train)
    y_pred = clf.predict(X_test_svm)
    print("Accuracy SVM : ", metrics.accuracy_score(y_test, y_pred))
    conf_mat = confusion_matrix(y_test, y_pred)
    print("NPV : ", NPV(conf_mat))
    print("PPV : ", PPV(conf_mat))
    print("Confusion Matrix:")
    print(conf_mat)
    print("Report:")
    print(classification_report(y_test, y_pred))
    # plotthreshold(clf,X_test_svm)
    # pplotthreshold(clf,X_test_svm)
    svc_disp = RocCurveDisplay.from_estimator(clf, X_test_svm, y_test)
    plt.show()
    if cv:
        print()
        scores = cross_val_score(clf, features, labels, cv=3)
        print("Cross validation cv=3", scores)
        print("Mean Accuracy:", scores.mean())


def RandomForest(features, labels, n, cv=True):
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels, test_size=0.3, random_state=109)
    print("Shape of samples: ", features.shape)
    print("traning  with test size=30%...")
    rf_w = RandomForestClassifier(
        random_state=100, min_samples_leaf=1, min_samples_split=2, n_estimators=n)
    rf_w.fit(X_train, y_train)
    y_pred_rf_w = rf_w.predict(X_test)
    print("Accuracy Random Forest : ",
          metrics.accuracy_score(y_test, y_pred_rf_w))
    conf_mat = confusion_matrix(y_test, y_pred_rf_w)
    print("NPV : ", NPV(conf_mat))
    print("PPV : ", PPV(conf_mat))
    print("Confusion Matrix:")
    print(conf_mat)
    print("Report:")
    print(classification_report(y_test, y_pred_rf_w))
    svc_disp = RocCurveDisplay.from_estimator(rf_w, X_test, y_test)
    plt.show()
    # plotthreshold(rf_w,X_test)
    # pplotthreshold(rf_w,X_test)
    if cv:
        print()
        scores = cross_val_score(rf_w, features, labels, cv=3)
        print("Cross validation cv=3: ", scores)
        print("Mean Accuracy:", scores.mean())


def MLP(features, labels, n, cv=True):
    features = Kbest(features, labels, n)
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels, test_size=0.3, random_state=109)
    print("Shape of samples: ", features.shape)
    print("Shape of Trainng samples: ", X_train.shape)
    print("Shape of Testing Samples: ", X_test.shape)
    print("traning...")
    classifier = MLPClassifier(hidden_layer_sizes=(
        150, 100, 50), max_iter=300, activation='relu', solver='adam', random_state=1)
    classifier.fit(X_train, y_train)
    y_pred = classifier.predict(X_test)
    print("Accuracy MLP: ", metrics.accuracy_score(y_test, y_pred))
    conf_mat = confusion_matrix(y_test, y_pred)
    print("NPV : ", NPV(conf_mat))
    print("PPV : ", PPV(conf_mat))
    print("Confusion Matrix:")
    print(conf_mat)
    print("Report:")
    print(classification_report(y_test, y_pred))
    svc_disp = RocCurveDisplay.from_estimator(classifier, X_test, y_test)
    plt.show()
    # @plotthreshold(classifier,X_test)
    # @pplotthreshold(classifier,X_test)
    if cv:
        print()
        scores = cross_val_score(classifier, features, labels, cv=3)
        print("Cross validation cv=3: ", scores)
        print("Mean Accuracy:", scores.mean())
