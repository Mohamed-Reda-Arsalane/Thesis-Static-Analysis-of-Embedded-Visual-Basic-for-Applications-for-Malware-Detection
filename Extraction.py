''' 
This file contains:
extract_data_features(file1, file2): reads csv file1 and file2 extracts the 54 features used in code analysis
         and writes them in Data\Code_analysis_malware.txt and Data\Code_analysis_benign.txt
extract_data_token_bow(file1, file2): reads csv file1 and file2 extracts the 314 features used in Bag of word
         feature extraction and writes them in Data\BOW.txt
extract_data_token_tfidf(file1, file2): reads csv file1 and file2 extracts the 314 features used in TFIDF
         feature extraction and writes them in Data\TFIDF.txt
         
'''


from Code_analysis import concatenate
from features import extract, tokeniz, TFIDF
import numpy as np
import pandas as pd
from math import log
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)


def extractcsvpd(filename):
    data = pd.read_csv(filename, error_bad_lines=False)
    name = data['sha256'].tolist()
    code = data['vbaData'].tolist()
    results = []
    results.append(name)
    results.append(code)
    return results


def tokenizecode(testcases, label):
    result = []
    result1 = []
    print(len(testcases[0]))
    for j in tqdm(range(10000)):
        temp = concatenate(testcases[1][j])
        result.append(temp)
    r = result
    for j in tqdm(range(len(r))):
        temp = []
        temp.append(label)
        temp.append(r[j])
        result1.append(temp)
    return result1


def extractcode(testcases, label):
    result = []
    print(len(testcases[0]))
    for j in tqdm(range(10000)):
        temp = []
        temp.append(label)
        temp.append(extract(concatenate(testcases[1][j])))
        result.append(temp)
    return result


def extract_data(file, label):
    temp = extractcsvpd(file)
    result = extractcode(temp, label)
    return result


def extract_data_token(file, label):
    temp = extractcsvpd(file)
    result = tokenizecode(temp, label)
    return result


def selectfeatures(features, indexs):
    result = []
    length = len(features[0])
    for w in features:
        temp = []
        for i in range(1, len(w)+1):
            if i in indexs:
                temp.append(w[i-1])
        result.append(temp)
    return result


def splitlist(list):
    list1 = []
    list2 = []
    for i in list:
        list1.append(i[0])
        list2.append(i[1])
    return list1, list2


def merge_shuffle(list1, list2):
    list = []
    for i in range(len(list1)):
        list.append(list1[i])
        list.append(list2[i])
    return list


def writefile(list, file):
    f = open(file, "w")
    for i in list:
        f.write(str(i)+"\n")
    f.close()


def readfile(file):
    f = open(file, "r")
    result = []
    for i in f:
        list = []
        line = i[1:-3].split(", [")
        list.append(int(line[0]))
        temp = []
        for j in line[1].split(", "):
            temp.append(float(j))
        list.append(temp)
        result.append(list)
    f.close()
    return result

# Code analysis feature extraction


def extract_data_features(file1, file2):
    ''' 
    reads csv file1 and file2 extracts the 54 features used in code analysis
    and writes them in Data\Code_analysis_malware.txt and Data\Code_analysis_benign.txt         
    '''
    malw = extract_data(file1, 1)
    writefile(malw, "Data\\Code_analysis_malware.txt")
    begi = extract_data(file2, 0)
    writefile(begi, "Data\\Code_analysis_benign.txt")

# TFIDF feature extraction


def extract_data_token_tfidf(file1, file2):
    ''' 
    reads csv file1 and file2 extracts the 314 features used in Bag of word
    feature extraction and writes them in Data\BOW.txt         
    '''
    malw = extract_data_token(file1, 1)
    begw = extract_data_token(file2, 0)

    result = []
    for i in range(len(malw)):
        result.append(malw[i])
        result.append(begw[i])

    print(len(result))

    code = []
    for i in range(len(result)):
        code.append(result[i][1])

    for i in range(len(code)):
        code[i] = code[i].replace('_\\r', ' ').replace(
            '\\r', '').replace('_\\n', '').replace('\\n', ' ')

    boolbow = False
    if boolbow:
        BOW = TFIDF(code)

        if len(result) == len(BOW):
            print("same")

        data = []
        for i in range(len(result)):
            temp = []
            temp.append(result[i][0])
            temp.append(list(BOW[i]))
            data.append(temp)

        print(len(data[1][1]))
        writefile(data, "Data\\TFIDF.txt")

# Bag of words feature extraction


def extract_data_token_bow(file1, file2):
    ''' 
    reads csv file1 and file2 extracts the 314 features used in TFIDF
    feature extraction and writes them in Data\TFIDF.txt         
    '''
    malw = extract_data_token(file1, 1)
    begw = extract_data_token(file2, 0)

    result = []
    for i in range(len(malw)):
        result.append(malw[i])
        result.append(begw[i])

    print(len(result))

    code = []
    for i in range(len(result)):
        code.append(result[i][1])

    for i in range(len(code)):
        code[i] = code[i].replace('_\\r', ' ').replace(
            '\\r', '').replace('_\\n', '').replace('\\n', ' ')

    boolbow = False
    if boolbow:
        BOW = tokeniz(code)
        if len(result) == len(BOW):
            print("same")

        data = []
        for i in range(len(result)):
            temp = []
            temp.append(result[i][0])
            temp.append(list(BOW[i]))
            data.append(temp)

        print(len(data[1][1]))
        writefile(data, "Data\\BOW.txt")


file1 = "I did not include the dataset in the submition of the code"
file2 = "I did not include the dataset in the submition of the code"


''' Extraction of features '''

extract_data_features(file1, file2)
extract_data_token_bow(file1, file2)
extract_data_token_tfidf(file1, file2)
